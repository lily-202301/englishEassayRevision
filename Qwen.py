import os
import base64
import json
import argparse
from openai import OpenAI

# ==========================================
# 1. é…ç½® API Key
# ==========================================
client = OpenAI(
    # âš ï¸ è¯·ç¡®è®¤æ­¤å¤„å¡«å…¥çš„æ˜¯æœ‰æ•ˆçš„ API Key
    api_key="sk-c1a452ab4ec14d42ba9dfc629ff0463d",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# ==========================================
# 2. å®šä¹‰å®Œæ•´çš„ System Prompt (é¡ºåºå·²è°ƒæ•´)
# ==========================================
SYSTEM_PROMPT = """
# Role Definition
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è‹±è¯­ä½œæ–‡é˜…å·ä¸“å®¶ã€‚å­¦ç”Ÿä¹¦å†™ä¹Ÿæ˜¯è¯„åˆ†çš„ä¾æ®ï¼Œä½ çš„ä»»åŠ¡æ˜¯é’ˆå¯¹æˆ‘æä¾›çš„ã€å­¦ç”Ÿè‹±è¯­ä½œæ–‡ã€‘ï¼ˆå›¾ç‰‡å½¢å¼ï¼‰ï¼ŒæŒ‰ç…§æŒ‡å®šçš„ç»´åº¦è¿›è¡Œæ·±åº¦æ‰¹æ”¹ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªä¸¥æ ¼ç¬¦åˆæ ¼å¼è¦æ±‚çš„ JSON æ•°æ®ã€‚

# Input Data
- å­¦ç”Ÿèº«ä»½ï¼šé«˜ä¸­ç”Ÿ
- ä½œæ–‡å†…å®¹ï¼šå›¾ç‰‡ä¸­çš„æ‰‹å†™æ–‡å­—ï¼ˆè‹¥æœ‰å¤šå¼ å›¾ç‰‡ï¼Œè¯·åˆå¹¶é˜…è¯»ï¼‰

# Task Requirements
è¯·ä»”ç»†é˜…è¯»ä½œæ–‡ï¼Œè¿›è¡Œå¤šç»´åº¦çš„åˆ†æï¼Œä½ éœ€è¦å®Œæˆä»¥ä¸‹ JSON å­—æ®µçš„å¡«å……ï¼š

1. **original_text**: ã€OCRè¯†åˆ«ã€‘å‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰‹å†™è‹±æ–‡ï¼Œå°†æ‰€æœ‰å›¾ç‰‡å†…å®¹åˆå¹¶ä¸ºä¸€æ®µå®Œæ•´çš„æ–‡æœ¬ã€‚
2. **overall_evaluation**: ç»™å‡ºæ¡£æ¬¡ã€æ€»åˆ†ã€ç®€çŸ­è¯„è¯­åŠå››ä¸ªç»´åº¦çš„ç»†åˆ†æ‰“åˆ†ã€‚
3. **highlights**: åˆ†æå†…å®¹ã€è¯­è¨€ã€ç»“æ„ä¸‰ä¸ªæ–¹é¢çš„äº®ç‚¹ã€‚
4. **improvements**: åˆ†æå†…å®¹ã€è¯­è¨€ã€ç»“æ„ä¸‰ä¸ªæ–¹é¢çš„å¾…æå‡ç‚¹ã€‚
5. **error_summary**: æ€»ç»“å‡ºç°çš„é”™è¯¯ç±»å‹ã€‚
6. **detailed_errors**: é€å¥åˆ—å‡ºå…·ä½“é”™è¯¯ã€ä¿®æ­£åŠè§£é‡Šã€‚
7. **optimizations**: é€‰å–è¡¨è¾¾å¹³æ·¡çš„å¥å­è¿›è¡Œå‡æ ¼æ¶¦è‰²ã€‚
8. **paragraph_reviews**: åˆ†æ®µç‚¹è¯„ã€‚
9. **material_reuse_guide**: ä¸€æå¤šç”¨åˆ†æã€‚
10. **revised_text**: ã€èŒƒæ–‡è¾“å‡ºã€‘åŸºäºåŸæ–‡ï¼Œåœ¨å¸çº³ä¸Šè¿°æ‰€æœ‰ä¿®æ”¹å»ºè®®åï¼Œè¾“å‡ºä¸€ç¯‡å®Œæ•´çš„ã€é«˜è´¨é‡çš„ä¿®æ­£ç‰ˆä½œæ–‡ã€‚

# Output Format (JSON Schema)
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼Œä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ï¼Œç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬ JSON å­—ç¬¦ä¸²ã€‚

{
  "original_text": "STRING: è¯†åˆ«åˆ°çš„ä½œæ–‡åŸæ–‡ï¼ˆåˆå¹¶æ‰€æœ‰å›¾ç‰‡å†…å®¹ï¼‰",
  "overall_evaluation": {
    "tier": "STRING: è¯„å®šæ¡£æ¬¡ (æœ€å¥½: ç¬¬äº”æ¡£, æœ€å·®: ç¬¬ä¸€æ¡£)",
    "total_score": "STRING: æ€»åˆ†ï¼ˆæ»¡åˆ†25åˆ†ï¼Œ5åˆ†ä¸ºä¸€ä¸ªåˆ†ç•Œï¼‰",
    "brief_comment": "STRING: 1-2å¥æ€»ä½“ç®€è¯„",
    "score_breakdown": {
      "relevance": "STRING: åˆ‡é¢˜ç¨‹åº¦",
      "grammar_vocab": "STRING: è¯­æ³•è¯æ±‡",
      "logic_structure": "STRING: é€»è¾‘ç»“æ„",
      "content": "STRING: å†…å®¹å……å®åº¦"
    }
  },
  "highlights": {
    "content": [ { "point": "STRING", "evidence": "STRING" } ],
    "language": [ { "point": "STRING", "evidence": "STRING" } ],
    "structure": [ { "point": "STRING", "description": "STRING" } ]
  },
  "improvements": {
    "content": [ { "point": "STRING", "description": "STRING" } ],
    "language": [ { "point": "STRING", "evidence": "STRING" } ],
    "structure": [ { "point": "STRING", "description": "STRING" } ]
  },
  "error_summary": {
    "grammar": ["STRING"],
    "spelling": ["STRING"],
    "structure": ["STRING"]
  },
  "detailed_errors": [
    {
      "id": "NUMBER",
      "type": "STRING",
      "original_sentence": "STRING",
      "correction": "STRING",
      "explanation": "STRING",
      "advanced_suggestion": "STRING"
    }
  ],
  "optimizations": [
    {
      "id": "NUMBER",
      "type": "STRING",
      "original_sentence": "STRING",
      "correction": "STRING",
      "explanation": "STRING"
    }
  ],
  "paragraph_reviews": [
    {
      "paragraph_index": "NUMBER",
      "summary": "STRING",
      "issues": "STRING",
      "specific_corrections": [ { "wrong": "STRING", "right": "STRING" } ]
    }
  ],
  "material_reuse_guide": {
    "applicable_themes": [
      {
        "theme": "STRING",
        "description": "STRING"
      }
    ],
    "processing_direction": "STRING",
    "expansion_ideas": "STRING"
  },
  "revised_text": "STRING: ã€æ­¤å¤„è¾“å‡ºæœ€ç»ˆçš„ä¿®æ­£ç‰ˆèŒƒæ–‡ã€‘"
}
"""


# ==========================================
# 3. åŠŸèƒ½å‡½æ•°
# ==========================================

def encode_image(image_path):
    """è¯»å–æœ¬åœ°å›¾ç‰‡å¹¶è½¬æ¢ä¸º Base64"""
    if not os.path.exists(image_path):
        print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {image_path}ï¼Œå·²è·³è¿‡")
        return None
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def grade_essay_multipage(image_path_list, prompt_text):
    """ä¸Šä¼ å¤šå¼ å›¾ç‰‡å¹¶è·å– JSON ç»“æœ"""

    # --- A. åŠ¨æ€æ„å»º content åˆ—è¡¨ ---
    user_content_list = []

    print(f"ğŸ”„ æ­£åœ¨è¯»å– {len(image_path_list)} å¼ å›¾ç‰‡...")

    # å…ˆå¾ªç¯å¤„ç†æ¯ä¸€å¼ å›¾ç‰‡
    for img_path in image_path_list:
        base64_str = encode_image(img_path)
        if base64_str:
            user_content_list.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_str}"
                }
            })

    # å¦‚æœæ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾ç‰‡ï¼Œç›´æ¥è¿”å›
    if not user_content_list:
        print("â›” é”™è¯¯ï¼šæ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡è¢«åŠ è½½ã€‚")
        return

    # æœ€åæŠŠæ–‡æœ¬æç¤ºè¯åŠ è¿›å»
    user_content_list.append({
        "type": "text",
        "text": prompt_text
    })

    # --- B. è°ƒç”¨ API ---
    print(f"ğŸš€ æ­£åœ¨å‘é€ {len(image_path_list)} å¼ å›¾ç‰‡ç»™ Qwen-VL-Max (è¯·è€å¿ƒç­‰å¾…)...")

    try:
        completion = client.chat.completions.create(
            model="qwen-vl-max",
            messages=[
                {
                    "role": "system",
                    # è¿™é‡Œä½¿ç”¨äº†ä¸Šé¢å®šä¹‰çš„å®Œæ•´ SYSTEM_PROMPT
                    "content": SYSTEM_PROMPT
                },
                {
                    "role": "user",
                    "content": user_content_list
                },
            ],
            temperature=0.2,  # é™ä½éšæœºæ€§ï¼Œä¿è¯ JSON æ ¼å¼ç¨³å®š
        )

        # è·å–åŸå§‹å†…å®¹
        raw_content = completion.choices[0].message.content

        # ç®€å•æ¸…æ´— markdown æ ‡è®°
        clean_content = raw_content.replace("```json", "").replace("```", "").strip()

        print("\nâœ… === æ‰¹æ”¹ç»“æœ (JSON) ===\n")
        print(clean_content)

        return clean_content

    except Exception as e:
        print(f"ğŸ’¥ API è°ƒç”¨å‡ºé”™: {e}")
        return None


# ==========================================
# 4. ä¸»ç¨‹åºå…¥å£
# ==========================================

if __name__ == "__main__":
    # =============================
    # 1. å‘½ä»¤è¡Œå‚æ•°è§£æ
    # =============================
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--out",
        type=str,
        default="qwen_essay_result.json",
        help="Qwen æ‰¹æ”¹ç»“æœ JSON çš„è¾“å‡ºè·¯å¾„",
    )
    parser.add_argument(
        "--images",
        nargs="+",
        help="ä½œæ–‡å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆä¸ä¼ å°±ç”¨ä»£ç é‡Œå†™æ­»çš„é»˜è®¤è·¯å¾„ï¼‰",
    )
    args = parser.parse_args()

    # =============================
    # 2. ç¡®å®šå›¾ç‰‡åˆ—è¡¨
    # =============================
    if args.images:
        # å¦‚æœé€šè¿‡å‘½ä»¤è¡Œä¼ äº†å›¾ç‰‡ï¼Œå°±ç”¨å‘½ä»¤è¡Œçš„
        my_images = args.images
    else:
        # å¦åˆ™ç”¨ä½ åŸæ¥å†™æ­»çš„é‚£ä¸¤å¼ 
        my_images = [
            r"G:\å¼€å‘é¡¹ç›®\AI_English\èµ„æ–™\ä¸­ç­‰\ä¸­ç­‰1-1.jpg",
            r"G:\å¼€å‘é¡¹ç›®\AI_English\èµ„æ–™\ä¸­ç­‰\ä¸­ç­‰1-2.jpg",
        ]

    # =============================
    # 3. è°ƒç”¨å¤§æ¨¡å‹æ‰¹æ”¹
    # =============================
    result_json_str = grade_essay_multipage(
        my_images,
        "è¿™æ˜¯å­¦ç”Ÿå†™çš„ä½œæ–‡ï¼Œå…±2é¡µï¼Œè¯·è¯†åˆ«å›¾ç‰‡å†…å®¹å¹¶ä¸¥æ ¼æŒ‰ç…§ System Prompt å®šä¹‰çš„ JSON æ ¼å¼è¿›è¡Œæ‰¹æ”¹ã€‚",
    )

    # =============================
    # 4. ä¿å­˜ JSON åˆ°æŒ‡å®š --out
    # =============================
    if result_json_str:
        try:
            # å…ˆå°è¯•è§£ææˆ dictï¼Œç¡®è®¤æ˜¯åˆæ³• JSON
            result_obj = json.loads(result_json_str)

            output_path = args.out  # âœ… ç”¨ runner.py ä¼ è¿›æ¥çš„è·¯å¾„

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼ˆruns/æ—¶é—´æˆ³/ï¼‰
            out_dir = os.path.dirname(output_path)
            if out_dir:
                os.makedirs(out_dir, exist_ok=True)

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(result_obj, f, ensure_ascii=False, indent=2)

            print(f"\nğŸ’¾ JSON ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°±æŠŠåŸå§‹å­—ç¬¦ä¸²å¦å­˜ä¸º .txt æ–¹ä¾¿æ’æŸ¥
            print("âš ï¸ JSON è§£æå¤±è´¥ï¼Œå·²å°†åŸå§‹å†…å®¹ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œæ–¹ä¾¿ä½ æ£€æŸ¥æ ¼å¼é—®é¢˜ã€‚")
            # raw æ–‡ä»¶ä»ç„¶æ”¾åœ¨åŒä¸€ç›®å½•ä¸‹
            fallback_path = (args.out or "qwen_essay_result.json") + ".raw.txt"
            with open(fallback_path, "w", encoding="utf-8") as f:
                f.write(result_json_str)
            print(f"ğŸ’¾ åŸå§‹å†…å®¹ä¿å­˜åˆ°: {fallback_path}")
            # é 0 é€€å‡ºç ï¼Œæ–¹ä¾¿ runner.py æ‰ç”¨æ—¶æ£€æŸ¥å¤±è´¥
            raise
