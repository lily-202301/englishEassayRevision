import os
import base64
import json
import uuid
import time
import subprocess
import dirtyjson
from datetime import datetime
from openai import OpenAI
from celery_utils import celery_app
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# 1. é…ç½®
# ==========================================
api_key = os.getenv("DASHSCOPE_API_KEY")
if not api_key:
    raise ValueError("é”™è¯¯ï¼šæ‰¾ä¸åˆ° API Keyã€‚...")

client = OpenAI(
    api_key=api_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    timeout=120.0,
    max_retries=3,
)

RUNS_FOLDER = 'runs'
if not os.path.exists(RUNS_FOLDER):
    os.makedirs(RUNS_FOLDER)

# ==========================================
# 2. æ ‡å‡†åŒ–ã€æ— æ­§ä¹‰çš„ System Prompt
# ==========================================
SYSTEM_PROMPT = """# Role Definition
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è‹±è¯­ä½œæ–‡é˜…å·ä¸“å®¶ã€‚å­¦ç”Ÿä¹¦å†™ä¹Ÿæ˜¯è¯„åˆ†çš„ä¾æ®ï¼Œä½ çš„ä»»åŠ¡æ˜¯é’ˆå¯¹æˆ‘æä¾›çš„[å­¦ç”Ÿè‹±è¯­ä½œæ–‡](å›¾ç‰‡å½¢å¼)ï¼ŒæŒ‰ç…§æŒ‡å®šçš„ç»´åº¦è¿›è¡Œæ·±åº¦æ‰¹æ”¹ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªä¸¥æ ¼ç¬¦åˆæ ¼å¼è¦æ±‚çš„ JSON æ•°æ®ã€‚

# Input Data
- å­¦ç”Ÿèº«ä»½ï¼šé«˜ä¸­ç”Ÿ
- ä½œæ–‡å†…å®¹ï¼šå›¾ç‰‡ä¸­çš„æ‰‹å†™æ–‡å­—(è‹¥æœ‰å¤šå¼ å›¾ç‰‡ï¼Œè¯·åˆå¹¶é˜…è¯»)

# Task Requirements
è¯·ä»”ç»†é˜…è¯»ä½œæ–‡ï¼Œè¿›è¡Œå¤šç»´åº¦çš„åˆ†æï¼Œä½ éœ€è¦å®Œæˆä»¥ä¸‹ JSON å­—æ®µçš„å¡«å……ï¼š

1. **original_text**: [OCRè¯†åˆ«]å‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰‹å†™è‹±æ–‡ï¼Œå°†æ‰€æœ‰å›¾ç‰‡å†…å®¹åˆå¹¶ä¸ºä¸€æ®µå®Œæ•´çš„æ–‡æœ¬ã€‚
2. **overall_evaluation**: ç»™å‡ºæ¡£æ¬¡ã€æ€»åˆ†ã€ç®€çŸ­è¯„è¯­åŠå››ä¸ªç»´åº¦çš„ç»†åˆ†æ‰“åˆ†ã€‚
3. **highlights**: åˆ†æå†…å®¹ã€è¯­è¨€ã€ç»“æ„ä¸‰ä¸ªæ–¹é¢çš„äº®ç‚¹ã€‚
4. **improvements**: åˆ†æå†…å®¹ã€è¯­è¨€ã€ç»“æ„ä¸‰ä¸ªæ–¹é¢çš„å¾…æå‡ç‚¹ã€‚
5. **error_summary**: æ€»ç»“å‡ºç°çš„é”™è¯¯ç±»å‹ã€‚
6. **detailed_errors**: é€å¥åˆ—å‡ºå…·ä½“é”™è¯¯ã€ä¿®æ­£åŠè§£é‡Šã€‚
7. **optimizations**: é€‰å–è¡¨è¾¾å¹³æ·¡çš„å¥å­è¿›è¡Œå‡æ ¼æ¶¦è‰²ã€‚
8. **paragraph_reviews**: åˆ†æ®µç‚¹è¯„ã€‚
9. **material_reuse_guide**: ä¸€æå¤šç”¨åˆ†æã€‚
10. **revised_text**: [èŒƒæ–‡è¾“å‡º]åŸºäºåŸæ–‡ï¼Œåœ¨å¸çº³ä¸Šè¿°æ‰€æœ‰ä¿®æ”¹å»ºè®®åï¼Œè¾“å‡ºä¸€ç¯‡å®Œæ•´çš„ã€é«˜è´¨é‡çš„ä¿®æ­£ç‰ˆä½œæ–‡ã€‚

# Output Format (JSON Schema)
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼Œä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ï¼Œç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬ JSON å­—ç¬¦ä¸²ã€‚

{
  "original_text": "STRING: è¯†åˆ«åˆ°çš„ä½œæ–‡åŸæ–‡(åˆå¹¶æ‰€æœ‰å›¾ç‰‡å†…å®¹)",
  "overall_evaluation": {
    "tier": "STRING: è¯„å®šæ¡£æ¬¡ (æœ€å¥½: ç¬¬äº”æ¡£, æœ€å·®: ç¬¬ä¸€æ¡£)",
    "total_score": "STRING: æ€»åˆ†(æ»¡åˆ†25åˆ†ï¼Œ5åˆ†ä¸ºä¸€ä¸ªåˆ†ç•Œ)",
    "brief_comment": "STRING: 1-2å¥æ€»ä½“ç®€è¯„",
    "score_breakdown": {
      "relevance": "STRING: åˆ‡é¢˜ç¨‹åº¦",
      "grammar_vocab": "STRING: è¯­æ³•è¯æ±‡",
      "logic_structure": "STRING: é€»è¾‘ç»“æ„",
      "content": "STRING: å†…å®¹å……å®åº¦"
    }
  },
  "highlights": {
    "content": [ { "point": "STRING", "evidence": "STRING" } ],
    "language": [ { "point": "STRING", "evidence": "STRING" } ],
    "structure": [ { "point": "STRING", "description": "STRING" } ]
  },
  "improvements": {
    "content": [ { "point": "STRING", "description": "STRING" } ],
    "language": [ { "point": "STRING", "evidence": "STRING" } ],
    "structure": [ { "point": "STRING", "description": "STRING" } ]
  },
  "error_summary": {
    "grammar": ["STRING"],
    "spelling": ["STRING"],
    "structure": ["STRING"]
  },
  "detailed_errors": [
    {
      "id": "NUMBER",
      "type": "STRING",
      "original_sentence": "STRING",
      "correction": "STRING",
      "explanation": "STRING",
      "advanced_suggestion": "STRING"
    }
  ],
  "optimizations": [
    {
      "id": "NUMBER",
      "type": "STRING",
      "original_sentence": "STRING",
      "correction": "STRING",
      "explanation": "STRING"
    }
  ],
  "paragraph_reviews": [
    {
      "paragraph_index": "NUMBER",
      "summary": "STRING",
      "issues": "STRING",
      "specific_corrections": [ { "wrong": "STRING", "right": "STRING" } ]
    }
  ],
  "material_reuse_guide": {
    "applicable_themes": [
      {
        "theme": "STRING",
        "description": "STRING"
      }
    ],
    "processing_direction": "STRING",
    "expansion_ideas": "STRING"
  },
  "revised_text": "STRING: [æ­¤å¤„è¾“å‡ºæœ€ç»ˆçš„ä¿®æ­£ç‰ˆèŒƒæ–‡]"
}
"""

# ==========================================
# 3. Celery ä»»åŠ¡ (æœ€ç»ˆä¿®å¤ç‰ˆ)
# ==========================================

@celery_app.task
def grade_essay_multipage(image_path_list, prompt_text):
    start_time = time.time()
    user_content_list = []
    for img_path in image_path_list:
        base64_str = encode_image(img_path)
        if base64_str:
            user_content_list.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_str}"}})
    if not user_content_list:
        return {"error": "No valid images loaded."}
    user_content_list.append({"type": "text", "text": prompt_text})
    try:
        completion = client.chat.completions.create(
            model="qwen-vl-max",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_content_list},
            ],
            temperature=0.2,
        )
        raw_content = completion.choices[0].message.content
        clean_content = raw_content.replace("```json", "").replace("```", "").strip()
        if not clean_content:
            raise ValueError("APIè¿”å›äº†ç©ºå†…å®¹")
        json_generation_time = time.time() - start_time
        print(f"âœ… [JSON Task] æ‰¹æ”¹å®Œæˆ, è€—æ—¶: {json_generation_time:.2f}s")
        return {"json_result": clean_content, "timing": {"json_generation": json_generation_time}}
    except Exception as e:
        print(f"ğŸ’¥ [JSON Task] API è°ƒç”¨å‡ºé”™: {e}")
        return {"error": str(e)}

@celery_app.task
def generate_pdf_report(previous_result):
    if 'error' in previous_result:
        return previous_result

    start_time = time.time()
    json_string = previous_result['json_result']

    run_dir = os.path.join(RUNS_FOLDER, datetime.now().strftime('%Y%m%d-%H%M%S') + f"_{uuid.uuid4().hex[:6]}")
    os.makedirs(run_dir, exist_ok=True)

    json_path = os.path.join(run_dir, "qwen_essay_result.json")
    pdf_path = os.path.join(run_dir, "essay_report.pdf")

    try:
        # 1. ä½¿ç”¨ dirtyjson å®¹é”™è§£æå¹¶ä¿å­˜JSON
        try:
            data = dirtyjson.loads(json_string)
        except Exception as e:
            with open(json_path + ".error.txt", "w", encoding="utf-8") as f:
                f.write(json_string)
            raise ValueError(f"LLMè¿”å›äº†æ— æ•ˆçš„JSONæ•°æ®ä¸”æ— æ³•è‡ªåŠ¨ä¿®å¤: {e}")
        
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        # 2. æ„å»ºå¹¶æ‰§è¡Œå‘½ä»¤è¡Œ
        command = [
            "node", 
            "export-pdf.js", 
            f"--json={json_path}", 
            f"--out={pdf_path}"
        ]
        print(f"ğŸ“„ [PDF Task] æ­£åœ¨æ‰§è¡Œå‘½ä»¤: {' '.join(command)}")
        
        result = subprocess.run(command, capture_output=True, text=True, check=True, shell=True)
        print(f"âœ… [PDF Task] export-pdf.js è„šæœ¬æ‰§è¡ŒæˆåŠŸã€‚")

        pdf_generation_time = time.time() - start_time
        print(f"âœ… [PDF Task] PDF å’Œ JSON å·²ä¿å­˜è‡³: {run_dir}")

        return {
            "json_path": json_path,
            "pdf_path": pdf_path,
            "timing": {
                "json_generation": previous_result['timing']['json_generation'],
                "pdf_generation": pdf_generation_time,
                "total": previous_result['timing']['json_generation'] + pdf_generation_time
            }
        }

    except subprocess.CalledProcessError as e:
        print(f"ğŸ’¥ [PDF Task] export-pdf.js è„šæœ¬æ‰§è¡Œå¤±è´¥:")
        print(f"--- STDOUT ---\n{e.stdout}")
        print(f"--- STDERR ---\n{e.stderr}")
        return {"error": f"PDF generation script failed: {e.stderr}"}
    except Exception as e:
        print(f"ğŸ’¥ [PDF Task] ç”Ÿæˆ PDF æ—¶å‡ºç°æ„å¤–é”™è¯¯: {e}")
        return {"error": f"PDF generation failed: {e}"} 


def encode_image(image_path):
    if not os.path.exists(image_path):
        return None
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')
